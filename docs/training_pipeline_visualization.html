<!DOCTYPE html>
<html lang="de">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Multimodale Trainingspipeline</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 1400px;
            margin: 0 auto;
            background: white;
            border-radius: 20px;
            box-shadow: 0 20px 40px rgba(0,0,0,0.1);
            overflow: hidden;
        }

        .header {
            background: linear-gradient(135deg, #4facfe 0%, #00f2fe 100%);
            color: white;
            text-align: center;
            padding: 30px;
        }

        .header h1 {
            font-size: 2.5em;
            font-weight: 300;
            margin-bottom: 10px;
        }

        .header p {
            font-size: 1.2em;
            opacity: 0.9;
        }

        .pipeline {
            padding: 40px;
        }

        .stage {
            display: flex;
            align-items: center;
            margin-bottom: 40px;
            position: relative;
        }

        /* .stage:not(:last-child)::after {
            content: '';
            position: absolute;
            left: 50%;
            bottom: -20px;
            transform: translateX(-50%);
            width: 2px;
            height: 20px;
            background: linear-gradient(to bottom, #4facfe, #00f2fe);
            z-index: 1;
        } */

        .stage-number {
            background: linear-gradient(135deg, #ff6b6b, #ee5a52);
            color: white;
            width: 60px;
            height: 60px;
            border-radius: 50%;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 1.5em;
            font-weight: bold;
            margin-right: 30px;
            box-shadow: 0 10px 20px rgba(255, 107, 107, 0.3);
            flex-shrink: 0;
        }

        .stage-content {
            flex: 1;
            background: white;
            border-radius: 15px;
            padding: 25px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.1);
            border-left: 5px solid #4facfe;
        }

        .stage-title {
            font-size: 1.5em;
            font-weight: 600;
            color: #2c3e50;
            margin-bottom: 15px;
            display: flex;
            align-items: center;
        }

        .stage-title .emoji {
            margin-right: 10px;
            font-size: 1.2em;
        }

        .stage-description {
            color: #5a6c7d;
            line-height: 1.6;
            margin-bottom: 20px;
        }

        .stage-details {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(250px, 1fr));
            gap: 15px;
        }

        .detail-box {
            background: linear-gradient(135deg, #f8f9ff, #e6efff);
            border-radius: 10px;
            padding: 15px;
            border-left: 4px solid #4facfe;
        }

        .detail-title {
            font-weight: 600;
            color: #2c3e50;
            margin-bottom: 8px;
            font-size: 0.95em;
        }

        .detail-content {
            color: #5a6c7d;
            font-size: 0.9em;
            line-height: 1.4;
        }

        .code-snippet {
            background: #2d3748;
            color: #e2e8f0;
            padding: 15px;
            border-radius: 8px;
            font-family: 'Monaco', 'Menlo', 'Ubuntu Mono', monospace;
            font-size: 0.85em;
            margin: 10px 0;
            overflow-x: auto;
        }

        .metrics {
            display: flex;
            gap: 20px;
            margin: 20px 0;
        }

        .metric {
            background: white;
            border-radius: 10px;
            padding: 15px;
            text-align: center;
            box-shadow: 0 5px 15px rgba(0,0,0,0.1);
            flex: 1;
        }

        .metric-value {
            font-size: 1.8em;
            font-weight: bold;
            color: #4facfe;
        }

        .metric-label {
            color: #5a6c7d;
            font-size: 0.9em;
            margin-top: 5px;
        }

        .architecture-grid {
            display: grid;
            grid-template-columns: repeat(3, 1fr);
            gap: 15px;
            margin-top: 20px;
        }

        .architecture-card {
            background: white;
            border: 2px solid #e2e8f0;
            border-radius: 10px;
            padding: 15px;
            text-align: center;
            transition: all 0.3s ease;
        }

        .architecture-card:hover {
            border-color: #4facfe;
            transform: translateY(-5px);
            box-shadow: 0 10px 25px rgba(79, 172, 254, 0.2);
        }

        .arch-name {
            font-weight: 600;
            color: #2c3e50;
            margin-bottom: 5px;
            font-size: 0.9em;
        }

        .arch-components {
            color: #5a6c7d;
            font-size: 0.8em;
        }

        .data-flow {
            display: flex;
            align-items: center;
            justify-content: space-between;
            margin: 20px 0;
            padding: 20px;
            background: linear-gradient(135deg, #667eea, #764ba2);
            border-radius: 15px;
            color: white;
        }

        .flow-step {
            text-align: center;
            flex: 1;
        }

        .flow-arrow {
            font-size: 2em;
            margin: 0 10px;
            opacity: 0.7;
        }

        .sequence-viz {
            background: #f8f9ff;
            border-radius: 10px;
            padding: 20px;
            margin: 15px 0;
        }

        .sequence-timeline {
            display: flex;
            align-items: center;
            margin: 10px 0;
        }

        .frame {
            width: 30px;
            height: 20px;
            margin: 2px;
            border-radius: 3px;
            position: relative;
        }

        .frame.current {
            background: #4facfe;
        }

        .frame.future {
            background: #ff6b6b;
        }

        .frame.context {
            background: #e2e8f0;
        }

        .label-preview {
            margin-top: 10px;
            font-size: 0.9em;
        }

        .performance-viz {
            background: linear-gradient(135deg, #667eea, #764ba2);
            color: white;
            border-radius: 15px;
            padding: 25px;
            margin: 20px 0;
        }

        .perf-title {
            text-align: center;
            font-size: 1.5em;
            font-weight: 600;
            margin-bottom: 20px;
        }

        .perf-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
        }

        .perf-card {
            background: rgba(255, 255, 255, 0.1);
            border-radius: 10px;
            padding: 15px;
            text-align: center;
        }

        .perf-metric {
            font-size: 1.4em;
            font-weight: bold;
            margin-bottom: 5px;
        }

        .highlight {
            background: linear-gradient(135deg, #ffeaa7, #fab1a0);
            padding: 2px 6px;
            border-radius: 4px;
            color: #2d3436;
            font-weight: 600;
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>Multimodale Trainingspipeline</h1>
            <p>Von rohen Fahrzeugdaten zu intelligenten Bremsvorhersage-Modellen</p>
        </div>

        <div class="pipeline">
            <!-- Stage 1: Raw Data Collection -->
            <div class="stage">
                <div class="stage-number">1</div>
                <div class="stage-content">
                    <div class="stage-title">
                        <span class="emoji">📊</span>
                        Rohdatenerfassung
                    </div>
                    <div class="stage-description">
                        Synchrone Aufzeichnung von Kamera- und Telemetriedaten während realer Fahrten. 
                        Das System erfasst kontinuierlich multimodale Datenströme mit präziser Zeitstempel-Synchronisation.
                    </div>
                    <div class="stage-details">
                        <div class="detail-box">
                            <div class="detail-title">📷 Kameradaten</div>
                            <div class="detail-content">
                                • 2 FPS Bilderfassung<br>
                                • 1920×1080 → ROI-Cropping<br>
                                • JPEG Kompression (Q=85)<br>
                                • Synchronisierte Timestamps
                            </div>
                        </div>
                        <div class="detail-box">
                            <div class="detail-title">🚗 OBD-II Telemetrie</div>
                            <div class="detail-content">
                                • SPEED, RPM, Load, Acc_Pos<br>
                                • Mode 22 BRAKE_SIGNAL<br>
                                • Feature Engineering (Gear, Brake Force)<br>
                                • 6 Hz Sampling Rate (Bluetooth)
                            </div>
                        </div>
                        <div class="detail-box">
                            <div class="detail-title">💾 Datenformat</div>
                            <div class="detail-content">
                                • CSV: telemetry.csv<br>
                                • Images: frame_XXXXXX.jpg<br>
                                • Strukturierte Ordner-Hierarchie<br>
                                • Timestamps für Synchronisation
                            </div>
                        </div>
                    </div>
                    <div class="data-flow">
                        <div class="flow-step">
                            <div>🎥</div>
                            <div>PiCamera2</div>
                        </div>
                        <div class="flow-arrow">+</div>
                        <div class="flow-step">
                            <div>🔌</div>
                            <div>OBD-II ELM327</div>
                        </div>
                        <div class="flow-arrow">→</div>
                        <div class="flow-step">
                            <div>⏰</div>
                            <div>Time Sync</div>
                        </div>
                        <div class="flow-arrow">→</div>
                        <div class="flow-step">
                            <div>💾</div>
                            <div>Speicherung</div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Stage 2: Auto-Annotation -->
            <div class="stage">
                <div class="stage-number">2</div>
                <div class="stage-content">
                    <div class="stage-title">
                        <span class="emoji">🎯</span>
                        Auto-Annotation mit gefinetuntem YOLO
                    </div>
                    <div class="stage-description">
                        Automatische Objektdetektion mit <span class="highlight">YOLO12n Boxy-Tune</span> (gefinetunet auf Boxy Dataset). 
                        Skalierbare Annotation von tausenden Bildern ohne manuelle Intervention.
                    </div>
                    <div class="stage-details">
                        <div class="detail-box">
                            <div class="detail-title">🤖 YOLO-Modell</div>
                            <div class="detail-content">
                                • YOLOv12n architecture<br>
                                • Boxy Dataset finetuning<br>
                                • Single class: "vehicle"<br>
                                • Confidence threshold: 0.25
                            </div>
                        </div>
                        <div class="detail-box">
                            <div class="detail-title">⚙️ Verarbeitung</div>
                            <div class="detail-content">
                                • Batch-Processing: GPU-optimiert<br>
                                • ROI-aware Detection<br>
                                • Bounding Box Extraktion<br>
                                • Confidence + Area Calculation
                            </div>
                        </div>
                        <div class="detail-box">
                            <div class="detail-title">📋 Output Format</div>
                            <div class="detail-content">
                                • annotations.csv pro Recording<br>
                                • class_ids, confidences, bboxes<br>
                                • Synchronized mit Telemetrie<br>
                                • Ready für Training Pipeline
                            </div>
                        </div>
                    </div>
                    <div class="code-snippet">
# Auto-Annotation Pipeline
python training/multimodal/auto_annotate.py \
    --recordings-dir data/recordings \
    --model boxyn1hard.pt \
    --confidence 0.25 \
    --img-size 704
                    </div>
                    <div class="metrics">
                        <div class="metric">
                            <div class="metric-value">~3ms</div>
                            <div class="metric-label">Pro Bild (H100 GPU)</div>
                        </div>
                        <div class="metric">
                            <div class="metric-value">0.25</div>
                            <div class="metric-label">Min. Confidence</div>
                        </div>
                        <div class="metric">
                            <div class="metric-value">704px</div>
                            <div class="metric-label">Input Size</div>
                        </div>
                    </div>
                </div>
            </div>

            <!-- Stage 3: Future Label Generation -->
            <div class="stage">
                <div class="stage-number">3</div>
                <div class="stage-content">
                    <div class="stage-title">
                        <span class="emoji">🔮</span>
                        Future Label Generation - "In die Zukunft schauen"
                    </div>
                    <div class="stage-description">
                        Innovative Supervision durch <span class="highlight">temporale Verschiebung</span>: 
                        Jeder Zeitpunkt erhält Labels basierend auf zukünftigen Fahrzeugzuständen (1-5 Sekunden ahead).
                    </div>
                    <div class="stage-details">
                        <div class="detail-box">
                            <div class="detail-title">🛑 Brake Labels</div>
                            <div class="detail-content">
                                • brake_1s, brake_2s, ..., brake_5s<br>
                                • Basiert auf BRAKE_SIGNAL=True<br>
                                • Binäre Klassifikation<br>
                                • Multi-Horizon Prediction
                            </div>
                        </div>
                        <div class="detail-box">
                            <div class="detail-title">⛵ Coast Labels</div>
                            <div class="detail-content">
                                • coast_1s, coast_2s, ..., coast_5s<br>
                                • ACCELERATOR_POS_D < 5%<br>
                                • Kosten-freie Fahrt Detection<br>
                                • Eco-Driving Optimization
                            </div>
                        </div>
                        <div class="detail-box">
                            <div class="detail-title">⏱️ Temporal Logic</div>
                            <div class="detail-content">
                                • 2 Hz Sampling Rate<br>
                                • Frame Offset Calculation<br>
                                • Boundary Handling<br>
                                • Zeitstempel-Validation
                            </div>
                        </div>
                    </div>
                    <div class="sequence-viz">
                        <div style="font-weight: 600; margin-bottom: 10px;">🕒 Temporale Label-Zuordnung:</div>
                        <div class="sequence-timeline">
                            <div>t=0:</div>
                            <div class="frame current" title="Aktueller Frame"></div>
                            <div class="frame context"></div>
                            <div class="frame future" title="brake_1s Label"></div>
                            <div class="frame future" title="brake_2s Label"></div>
                            <div class="frame future" title="brake_3s Label"></div>
                            <div class="frame future" title="brake_4s Label"></div>
                            <div class="frame future" title="brake_5s Label"></div>
                        </div>
                        <div class="label-preview">
                            <strong>Label Extraktion:</strong> Frame t=0 erhält Labels basierend auf Bremsereignissen bei t+1s, t+2s, t+3s, t+4s, t+5s
                        </div>
                    </div>
                    <div class="code-snippet">
# Future Label Generation
for horizon in [1, 2, 3, 4, 5]:
    offset = int(horizon * SAMPLING_RATE_HZ)  # 2 FPS
    future_idx = current_idx + offset
    
    brake_label = telemetry.iloc[future_idx]['BRAKE_SIGNAL']
    coast_label = telemetry.iloc[future_idx]['ACCELERATOR_POS_D'] < 10.0
                    </div>
                </div>
            </div>

            <!-- Stage 4: Sequence Extraction -->
            <div class="stage">
                <div class="stage-number">4</div>
                <div class="stage-content">
                    <div class="stage-title">
                        <span class="emoji">📦</span>
                        Sequenzextraktion und Datenaufbereitung
                    </div>
                    <div class="stage-description">
                        Konversion von Zeitreihen-Daten in <span class="highlight">Sliding Window Sequenzen</span> 
                        für temporale ML-Modelle. Optimierte HDF5-Speicherung für effizientes Training.
                    </div>
                    <div class="stage-details">
                        <div class="detail-box">
                            <div class="detail-title">🪟 Sliding Windows</div>
                            <div class="detail-content">
                                • Sequence Length: 20 Frames<br>
                                • Stride: 4 Frames (Overlap)<br>
                                • Kontinuitäts-Validation<br>
                                • Boundary-aware Extraction
                            </div>
                        </div>
                        <div class="detail-box">
                            <div class="detail-title">🎯 Detection Tensors</div>
                            <div class="detail-content">
                                • Max 12 Objects pro Frame<br>
                                • 7D Feature Vector pro Object<br>
                                • Padding für variable Anzahl<br>
                                • Boolean Masking System
                            </div>
                        </div>
                        <div class="detail-box">
                            <div class="detail-title">💾 HDF5 Format</div>
                            <div class="detail-content">
                                • train.h5, val.h5, test.h5<br>
                                • Komprimierte Speicherung<br>
                                • Metadaten preservation<br>
                                • Efficient Batch Loading
                            </div>
                        </div>
                    </div>
                    <div class="sequence-viz">
                        <div style="font-weight: 600; margin-bottom: 10px;">📊 Sequenz-Struktur:</div>
                        <div class="metrics">
                            <div class="metric">
                                <div class="metric-value">20</div>
                                <div class="metric-label">Frames/Seq</div>
                            </div>
                            <div class="metric">
                                <div class="metric-value">12</div>
                                <div class="metric-label">Max Objects</div>
                            </div>
                            <div class="metric">
                                <div class="metric-value">7</div>
                                <div class="metric-label">Features/Object</div>
                            </div>
                            <div class="metric">
                                <div class="metric-value">10</div>
                                <div class="metric-label">Label Tasks</div>
                            </div>
                        </div>
                        <div style="margin-top: 15px; color: #5a6c7d;">
                            <strong>Tensor Shapes:</strong><br>
                            • Telemetry: [batch, 20, 8]<br>
                            • Detections: [batch, 20, 12, 7]<br>
                            • Masks: [batch, 20, 12]<br>
                            • Labels: [batch, 10] (brake_1s...brake_5s, coast_1s...coast_5s)
                        </div>
                    </div>
                </div>
            </div>

            <!-- Stage 5: Architecture Training -->
            <div class="stage">
                <div class="stage-number">5</div>
                <div class="stage-content">
                    <div class="stage-title">
                        <span class="emoji">🧠</span>
                        Systematisches Architektur-Training
                    </div>
                    <div class="stage-description">
                        <span class="highlight">Modulare Kombinatorik</span> von Encoder, Fusion und Decoder Komponenten. 
                        Systematische Evaluation aller 12 Architektur-Varianten für optimale Performance.
                    </div>
                    <div class="architecture-grid">
                        <div class="architecture-card">
                            <div class="arch-name">Simple + Concat + LSTM</div>
                            <div class="arch-components">Baseline • Fast • Robust</div>
                        </div>
                        <div class="architecture-card">
                            <div class="arch-name">Simple + Concat + Transformer</div>
                            <div class="arch-components">Parallel Processing</div>
                        </div>
                        <div class="architecture-card">
                            <div class="arch-name">Simple + CrossAttn + LSTM</div>
                            <div class="arch-components">Cross-Modal Fusion</div>
                        </div>
                        <div class="architecture-card">
                            <div class="arch-name">Simple + CrossAttn + Transformer</div>
                            <div class="arch-components">Advanced Attention</div>
                        </div>
                        <div class="architecture-card">
                            <div class="arch-name">Simple + Query + LSTM</div>
                            <div class="arch-components">Learnable Queries</div>
                        </div>
                        <div class="architecture-card">
                            <div class="arch-name">Simple + Query + Transformer</div>
                            <div class="arch-components">DETR-inspired</div>
                        </div>
                        <div class="architecture-card">
                            <div class="arch-name">Attention + Concat + LSTM</div>
                            <div class="arch-components">Self-Attention Input</div>
                        </div>
                        <div class="architecture-card">
                            <div class="arch-name">Attention + Concat + Transformer</div>
                            <div class="arch-components">Full Attention Stack</div>
                        </div>
                        <div class="architecture-card">
                            <div class="arch-name">Attention + CrossAttn + LSTM</div>
                            <div class="arch-components">Dual Attention</div>
                        </div>
                        <div class="architecture-card">
                            <div class="arch-name">Attention + CrossAttn + Transformer</div>
                            <div class="arch-components">Maximum Expressivity</div>
                        </div>
                        <div class="architecture-card">
                            <div class="arch-name">Attention + Query + LSTM</div>
                            <div class="arch-components">Query-based Attention</div>
                        </div>
                        <div class="architecture-card">
                            <div class="arch-name">Attention + Query + Transformer</div>
                            <div class="arch-components">State-of-the-Art</div>
                        </div>
                    </div>
                    <div class="code-snippet">
Systematisches Training aller Varianten durch Model Factory
                    </div>
                </div>
            </div>

            <!-- Stage 6: Performance Analysis -->
            <div class="stage">
                <div class="stage-number">6</div>
                <div class="stage-content">
                    <div class="stage-title">
                        <span class="emoji">📊</span>
                        Performance-Evaluation und Model Selection
                    </div>
                    <div class="stage-description">
                        Umfassende Evaluation aller trainierten Modelle unter <span class="highlight">Hardware-Constraints</span>. 
                        Multi-Metrik Assessment für optimale Model Selection.
                    </div>
                    <div class="performance-viz">
                        <div class="perf-title">🎯 Evaluation Metriken</div>
                        <div class="perf-grid">
                            <div class="perf-card">
                                <div class="perf-metric">Accuracy</div>
                                <div>Multi-Horizon Brake Prediction</div>
                            </div>
                            <div class="perf-card">
                                <div class="perf-metric">Latenz</div>
                                <div>Real-Time Constraint (&lt;100ms)</div>
                            </div>
                            <div class="perf-card">
                                <div class="perf-metric">Memory</div>
                                <div>Raspberry Pi 5 (8GB)</div>
                            </div>
                            <div class="perf-card">
                                <div class="perf-metric">F1-Score</div>
                                <div>Precision-Recall Balance</div>
                            </div>
                            <div class="perf-card">
                                <div class="perf-metric">AUC-ROC</div>
                                <div>Classification Performance</div>
                            </div>
                            <div class="perf-card">
                                <div class="perf-metric">Hardware</div>
                                <div>Edge Deployment Ready</div>
                            </div>
                        </div>
                    </div>
                    <div class="stage-details">
                        <div class="detail-box">
                            <div class="detail-title">🏆 Model Selection</div>
                            <div class="detail-content">
                                • Multi-Criteria Decision Analysis<br>
                                • Pareto-Optimal Performance<br>
                                • Hardware-Constraint Integration<br>
                                • Production-Ready Validation
                            </div>
                        </div>
                        <div class="detail-box">
                            <div class="detail-title">📈 Ablation Studies</div>
                            <div class="detail-content">
                                • Component-wise Analysis<br>
                                • Feature Importance Ranking<br>
                                • Architecture Impact Assessment<br>
                                • Training Strategy Optimization
                            </div>
                        </div>
                        <div class="detail-box">
                            <div class="detail-title">🚀 Deployment</div>
                            <div class="detail-content">
                                • ONNX Model Export<br>
                                • TensorRT Optimization<br>
                                • Raspberry Pi Integration<br>
                                • Real-Time Performance Validation
                            </div>
                        </div>
                    </div>
                </div>
            </div>
        </div>
    </div>

    <script>
        // Add some interactive hover effects
        document.querySelectorAll('.architecture-card').forEach(card => {
            card.addEventListener('mouseenter', function() {
                this.style.transform = 'translateY(-5px) scale(1.02)';
                this.style.boxShadow = '0 15px 30px rgba(79, 172, 254, 0.3)';
            });
            
            card.addEventListener('mouseleave', function() {
                this.style.transform = 'translateY(0) scale(1)';
                this.style.boxShadow = 'none';
            });
        });

        // Add animation to metrics
        const observerOptions = {
            threshold: 0.1,
            rootMargin: '0px 0px -100px 0px'
        };

        const observer = new IntersectionObserver((entries) => {
            entries.forEach(entry => {
                if (entry.isIntersecting) {
                    entry.target.style.opacity = '1';
                    entry.target.style.transform = 'translateY(0)';
                }
            });
        }, observerOptions);

        document.querySelectorAll('.stage').forEach(stage => {
            stage.style.opacity = '0';
            stage.style.transform = 'translateY(30px)';
            stage.style.transition = 'all 0.6s ease';
            observer.observe(stage);
        });
    </script>
</body>
</html>